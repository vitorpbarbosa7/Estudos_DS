{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyP+T4Q4vUVCqDOWKxK4j6Xr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"z5FRnA55HXnj","executionInfo":{"status":"ok","timestamp":1626536263045,"user_tz":180,"elapsed":9920,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjz4IKukhSl48ttoF6xu4-vG27Mk4RP8NDQwoLkZQ=s64","userId":"14860641237882865827"}},"outputId":"d2bacb7f-f221-4b9d-a59e-fb99bf01911e","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install shap"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting shap\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f4/c5b95cddae15be80f8e58b25edceca105aa83c0b8c86a1edad24a6af80d3/shap-0.39.0.tar.gz (356kB)\n","\r\u001b[K     |█                               | 10kB 9.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 6.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 102kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 143kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 163kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 174kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 194kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 204kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 215kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 225kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 235kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 245kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 256kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 276kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 286kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 296kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 307kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 317kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 327kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 337kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 348kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 3.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n","Collecting slicer==0.0.7\n","  Downloading https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n","Building wheels for collected packages: shap\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491615 sha256=ed6790bdf081ca05831b93cc2d9279e495f63fbef723f50c18fe97412ba03625\n","  Stored in directory: /root/.cache/pip/wheels/15/27/f5/a8ab9da52fd159aae6477b5ede6eaaec69fd130fa0fa59f283\n","Successfully built shap\n","Installing collected packages: slicer, shap\n","Successfully installed shap-0.39.0 slicer-0.0.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DF9MoB65G_C2","executionInfo":{"status":"ok","timestamp":1626536272985,"user_tz":180,"elapsed":9942,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjz4IKukhSl48ttoF6xu4-vG27Mk4RP8NDQwoLkZQ=s64","userId":"14860641237882865827"}}},"source":["import shap\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost.sklearn import XGBRegressor\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","from sklearn import tree\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Load Data\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3t8h9qGHVyv"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PYLaId4vHRT9"},"source":["\n","# reading the data\n","df = pd.read_csv('Train.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0Qor7xtHSwf"},"source":["\n","# imputing missing values in Item_Weight by median and Outlet_Size with mode\n","df['Item_Weight'].fillna(df['Item_Weight'].median(), inplace=True)\n","df['Outlet_Size'].fillna(df['Outlet_Size'].mode()[0], inplace=True)\n","\n","\n","df['Item_Identifier']\n","\n","df['Item_Type_Combined'] = df['Item_Identifier'].apply(lambda df: df[0:2])\n","\n","df['Item_Type_Combined'].value_counts()\n","\n","df['Item_Type_Combined'] = df['Item_Type_Combined'].map({'FD':'Food',\n","                                                       'NC':'Non-Consumable',\n","                                                        'DR':'Drinks'})\n","\n","df['Item_Type_Combined'].value_counts()\n","\n","# operating years of the store\n","df['Outlet_Years'] = 2013 - df['Outlet_Establishment_Year']\n","\n","# modifying categories of Item_Fat_Content\n","df['Item_Fat_Content'] = df['Item_Fat_Content'].replace({'LF':'Low Fat', 'reg':'Regular', 'low fat':'Low Fat'})\n","df['Item_Fat_Content'].value_counts()\n","\n","list(df)\n","\n","# label encoding the ordinal variables\n","le = LabelEncoder()\n","df['Outlet'] = le.fit_transform(df['Outlet_Identifier'])\n","var_mod = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet']\n","le = LabelEncoder()\n","\n","for i in var_mod:\n","    df[i] = le.fit_transform(df[i])\n","\n","df.shape\n","\n","list(df)\n","\n","fts = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Outlet_Type','Item_Type_Combined','Outlet']\n","\n","# one hot encoding the remaining categorical variables \n","df = pd.get_dummies(df, columns=fts)\n","\n","list(df)\n","\n","# dropping the ID variables and variables that have been used to extract new variables\n","df.drop(['Item_Type','Outlet_Establishment_Year', 'Item_Identifier', 'Outlet_Identifier'],axis=1,inplace=True)\n","\n","# separating the dependent and independent variables\n","X = df.drop('Item_Outlet_Sales',1)\n","y = df['Item_Outlet_Sales']\n","\n","# creating the training and validation set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)\n","\n","# Need to load JS vis in the notebook\n","shap.initjs()\n","\n","xgb_model = XGBRegressor(n_estimators=1000, max_depth=10, learning_rate=0.001, random_state=0)\n","xgb_model.fit(X_train, y_train)\n","\n","y_predict = xgb_model.predict(X_test)\n","\n","mean_squared_error(y_test, y_predict)**(0.5)\n","\n","# Visualize SHAP\n","\n","explainer = shap.TreeExplainer(xgb_model)\n","\n","explainer\n","\n","explainer.model\n","\n","explainer.shap_values\n","\n","explainer.expected_value\n","\n","shap_values = explainer.shap_values(X_train)\n","\n","shap_values"],"execution_count":null,"outputs":[]}]}